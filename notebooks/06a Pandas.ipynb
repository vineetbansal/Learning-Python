{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pandas\n",
    "[pandas](https://pandas.pydata.org/) is the primary Python library for doing basic data analysis. If you are a data scientist, much of your life will be spent manipulating data in pandas. pandas provides a nice layering on top of NumPy to make data analysis much easier. In particular, the primary data structure, the **DataFrame** provides labels for both the rows and the columns. This makes for much easier access to the elements within.\n",
    "\n",
    "### Iowa Housing Dataset\n",
    "We will use the [Iowa Housing Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) from Kaggle, a dataset of ~1500 homes in Ames, Iowa, with fields like the Sale Price, Area of floors, No. of rooms, Sale Date etc. Make sure to check out the [data description file](datasets/iowa_housing_data_description.txt) to get an idea of the kind of fields included in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (9.0, 5.0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# It's a convention to import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame by reading in a csv file\n",
    "data = pd.read_csv('datasets/iowa_housing.csv')\n",
    "# Like Numpy arrays, DataFrames have a 'shape' (# of rows, # of columns)\n",
    "print(data.shape)\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components of the DataFrame\n",
    "The vast majority of an analysis takes place inside a DataFrame. There are three components to a DataFrame, the **index**, the **columns** and the **data** or **values**. The index labels the rows, the column names label the columns and the data are the actual values that we manipulate during an analysis.\n",
    "\n",
    "![anatomy](dataframe_anatomy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 3 main components of a DataFrame\n",
    "#   1. The index - tells us how to locate (\"index into\") rows (axis 0).\n",
    "#   2. The columns - tell us how to locate (\"index into\") columns (axis 1).\n",
    "#   3. The values - the data itself\n",
    "\n",
    "print(data.index)     # An Index object that allows for fast searching\n",
    "print(data.columns)   # An Index object that allows for fast searching\n",
    "print(data.values)    # Note: What is the type of the 'values'? A numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can ask the DataFrame to 'describe' itself to get a general idea about the column ranges\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'head' method gives us the first 5 rows of the DataFrame\n",
    "# We could also obtain the first 5 rows by indexing into the DataFrame using iloc\n",
    "# Remember this slicing syntax from before?\n",
    "data.iloc[0:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like there is already an 'Id' column in our data\n",
    "# This is a more 'natural' index into the data than the one that was\n",
    "# created when we imported the data.\n",
    "# So let's set the index of our data to this columns\n",
    "data = data.set_index('Id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a subset of the columns of the DataFrame\n",
    "data[['LotArea', 'GrLivArea', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical vs Continuous\n",
    "Data can be categorized into two broad types. Data that is discrete and countable is called **categorical**. These variables usually have strings as values but sometimes numeric values like year or age may be considered categorical. **Continuous** variables on the other hand are always numeric and are uncountable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Single Columns of Data - A Series\n",
    "Each column of data may be selected with the indexing operator [] and a passed string name. A pandas **Series** is a single dimensional data structure with an index and values. It has no columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab single columns\n",
    "sale_price = data['SalePrice']\n",
    "print(type(sale_price))\n",
    "sale_price.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sort the Series object by it's values so we can get an idea of the most expensive homes\n",
    "sale_price = sale_price.sort_values(ascending=False)\n",
    "sale_price.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can describe a Series object just like we described the DataFrame\n",
    "sale_price.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting directly from pandas\n",
    "DataFrames conveniently provide a plot method to directly plot without using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of SalePrice data\n",
    "data['SalePrice'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Scatter plot of GrLivArea (Living Area over grade) vs. the Sale Price\n",
    "data.plot(kind='scatter', x='GrLivArea', y='SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting the values of categorical data\n",
    "The **`value_counts`** method is valuable for getting an idea of the distribution of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = data['Neighborhood']\n",
    "neighborhoods.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Data\n",
    "We can use the indexing operator [] and *Boolean Indexing* to zero on the data that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe what we get back when we do a comparison like this:\n",
    "data['SalePrice'] < 300000\n",
    "# We can use this Boolean Series (with an index identical to that of the DataFrame) to index into the the DataFrame\n",
    "# This is called Boolean Indexing, and works very similar to Boolean Indexing in Numpy\n",
    "affordable_data = data[data['SalePrice'] < 300000]\n",
    "affordable_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we're only interested in a subset of the data, both in terms of rows and columns\n",
    "\n",
    "# We're only interested in Cheap Homes built on or after 2005\n",
    "data_subset = data[(data['SalePrice'] < 300000) & (data['YearBuilt']>=2005)]\n",
    "# We're only interestd in the Neighborhood/Living Area/Sale Price columns\n",
    "data_subset = data_subset[['Neighborhood', 'GrLivArea', 'SalePrice']]\n",
    "data_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find out the mean of all the columns in our restricted dataset\n",
    "# Note the 'axis' parameter here - we get the mean for all the rows\n",
    "print(data_subset.mean(axis=0))\n",
    "\n",
    "# What would the following give us?\n",
    "# print(data_subset.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Aggregating\n",
    "One of the most common operations during an analysis is to divide the data into groups and aggregate some other dimension of data. For instance, to calculate the average sale price by neighborhood we can do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_neighborhood_prices = data_subset.groupby('Neighborhood').mean()\n",
    "print(mean_neighborhood_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Data\n",
    "Both DataFrame and Series object can be sorted by using the *sort_values* method, which returns a new DataFrame or Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the most expensive neigborhoods corresponding to our search criteria.\n",
    "print(mean_neighborhood_prices.sort_values(by=['SalePrice'], ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
